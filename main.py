import urllib.request
from urllib.parse import urlparse, quote, parse_qs
import re
import os
from datetime import datetime, timedelta, timezone
import opencc
import ssl
import sys
import socket
import time
import concurrent.futures
from typing import List, Dict, Set, Tuple

# è·³è¿‡SSLè¯ä¹¦éªŒè¯
ssl._create_default_https_context = ssl._create_unverified_context

# æ‰§è¡Œå¼€å§‹æ—¶é—´
timestart = datetime.now()

# è®¾ç½®æ ‡å‡†è¾“å‡ºå’Œé”™è¯¯è¾“å‡ºç«‹å³åˆ·æ–°
sys.stdout = os.fdopen(sys.stdout.fileno(), 'w', 1)
sys.stderr = os.fdopen(sys.stderr.fileno(), 'w', 1)

print("è„šæœ¬å¼€å§‹æ‰§è¡Œ")

# è¯»å–æ–‡æœ¬æ–¹æ³•
def read_txt_to_array(file_name: str) -> List[str]:
    encodings = ['utf-8-sig', 'gbk', 'latin-1']
    for encoding in encodings:
        try:
            with open(file_name, 'r', encoding=encoding) as file:
                return [line.strip() for line in file.readlines() if line.strip()]
        except UnicodeDecodeError:
            continue
        except FileNotFoundError:
            print(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_name}")
            return []
    print(f"æ— æ³•è¯»å–æ–‡ä»¶: {file_name}")
    return []

# è¯»å–åå•æ–‡ä»¶
def read_list_from_txt(file_path: str, is_blacklist: bool = True) -> List[str]:
    lines = read_txt_to_array(file_path)
    result = []
    for line in lines:
        if ',' in line:
            url = line.split(',')[1].strip()
            result.append(url)
        else:
            result.append(line)
    return result

# è¯»å–é¢‘é“å­—å…¸
def load_channel_dictionaries() -> Dict[str, List[str]]:
    dictionaries = {}
    categories = {
        'zh': 'ä¸»é¢‘é“/ç»¼åˆé¢‘é“.txt',
        'ys': 'ä¸»é¢‘é“/å¤®è§†é¢‘é“.txt',
        'ws': 'ä¸»é¢‘é“/å«è§†é¢‘é“.txt',
        'dy': 'ä¸»é¢‘é“/ç”µå½±.txt',
        'gj': 'ä¸»é¢‘é“/å›½é™…å°.txt',
        'zb': 'ä¸»é¢‘é“/ç›´æ’­ä¸­å›½.txt',
        'gd': 'åœ°æ–¹å°/å¹¿ä¸œé¢‘é“.txt',
        'hain': 'åœ°æ–¹å°/æµ·å—é¢‘é“.txt'
    }
    
    for key, path in categories.items():
        dictionaries[key] = read_txt_to_array(path)
    
    return dictionaries

# ç®€ç¹è½¬æ¢
def traditional_to_simplified(text: str) -> str:
    try:
        converter = opencc.OpenCC('t2s')
        return converter.convert(text)
    except Exception as e:
        print(f"ç®€ç¹è½¬æ¢å‡ºé”™: {e}")
        return text

# M3Uæ ¼å¼åˆ¤æ–­å’Œè½¬æ¢
def process_m3u_content(text: str) -> str:
    if not text.strip().startswith("#EXTM3U"):
        return text
    
    lines = text.split('\n')
    result = []
    channel_name = ""
    
    for line in lines:
        if line.startswith("#EXTINF"):
            channel_name = line.split(',')[-1].strip()
        elif line.startswith(("http", "rtmp", "p3p")):
            result.append(f"{channel_name},{line.strip()}")
        elif "#genre#" not in line and "," in line and "://" in line:
            result.append(line)
    
    return '\n'.join(result)

# æ¸…ç†é¢‘é“åç§°
removal_list = ["ã€ŒIPV4ã€", "ã€ŒIPV6ã€", "[ipv6]", "[ipv4]", "_ç”µä¿¡", "ç”µä¿¡", "ï¼ˆHDï¼‰", "[è¶…æ¸…]", "é«˜æ¸…", "è¶…æ¸…", "-HD", "(HK)", "AKtv", "@", "IPV6", "ğŸğŸğŸğŸğŸğŸğŸğŸï¸", "ğŸ¦ğŸ¦ğŸ¦ğŸ¦ğŸ¦ğŸ¦ğŸ¦ğŸ¦", " ", "[BD]", "[VGA]", "[HD]", "[SD]", "(1080p)", "(720p)", "(480p)"]

def clean_channel_name(channel_name: str) -> str:
    for item in removal_list:
        channel_name = channel_name.replace(item, "")
    replacements = {
        "CCTV0": "CCTV-",
        "PLUS": "+",
        "NewTV-": "NewTV",
        "iHOT-": "iHOT",
        "NEW": "New",
        "New_": "New"
    }
    for old, new in replacements.items():
        channel_name = channel_name.replace(old, new)
    return channel_name

# ç”Ÿæˆé¢‘é“IDï¼ˆç”¨äºEPGå’ŒLOGOï¼‰
def generate_channel_id(channel_name: str) -> str:
    # å¤„ç†CCTVé¢‘é“
    if channel_name.startswith('CCTV'):
        match = re.search(r'CCTV[-\s]*(\d+)', channel_name)
        if match:
            return f"CCTV{match.group(1)}"
    
    # å¤„ç†å…¶ä»–é¢‘é“
    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦å’Œç©ºæ ¼
    channel_id = re.sub(r'[^\w]', '', channel_name)
    return channel_id

# ç›´æ’­æºéªŒè¯å‡½æ•°
def validate_stream_url(url: str, timeout: int = 3) -> Tuple[bool, float]:
    try:
        start_time = time.time()
        
        parsed_url = urlparse(url)
        host = parsed_url.hostname
        port = parsed_url.port or (443 if parsed_url.scheme == 'https' else 80)
        
        # TCPè¿æ¥æµ‹è¯•
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(timeout)
        result = sock.connect_ex((host, port))
        sock.close()
        
        if result != 0:
            return False, None
            
        # HTTP/HTTPSéªŒè¯
        if url.startswith(('http://', 'https://')):
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': '*/*',
                'Connection': 'close',
                'Range': 'bytes=0-1024'
            }
            
            req = urllib.request.Request(url, headers=headers)
            with urllib.request.urlopen(req, timeout=timeout) as response:
                if response.getcode() not in [200, 206]:
                    return False, None
                
                content_type = response.headers.get('Content-Type', '')
                if not any(x in content_type for x in ['video', 'audio', 'application/octet-stream', 'application/vnd.apple.mpegurl']):
                    return False, None
                    
        end_time = time.time()
        return True, end_time - start_time
        
    except Exception as e:
        return False, None

# é¢‘é“æºç®¡ç†å™¨
class ChannelSourceManager:
    def __init__(self, blacklist: Set[str] = None):
        self.sources = {}
        self.seen_urls = set()
        self.blacklist = blacklist if blacklist else set()
        
    def add_source(self, channel_name: str, url: str, skip_validation: bool = False) -> bool:
        if url in self.seen_urls:
            return False
            
        # é»‘åå•æ£€æŸ¥
        if url in self.blacklist:
            return False
            
        self.seen_urls.add(url)
        
        if channel_name not in self.sources:
            self.sources[channel_name] = []
        
        if skip_validation:
            self.sources[channel_name].insert(0, (0, url))
        else:
            self.sources[channel_name].append((float('inf'), url))
        
        return True
        
    def validate_and_sort_sources(self, max_workers: int = 20) -> None:
        print("å¼€å§‹éªŒè¯æ‰€æœ‰æºçš„æœ‰æ•ˆæ€§...")
        
        all_urls = []
        url_to_channel = {}
        
        for channel_name, url_list in self.sources.items():
            for response_time, url in url_list:
                if response_time == float('inf'):
                    all_urls.append(url)
                    url_to_channel[url] = channel_name
        
        validated_results = {}
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_url = {executor.submit(validate_stream_url, url): url for url in all_urls}
            for future in concurrent.futures.as_completed(future_to_url):
                url = future_to_url[future]
                try:
                    is_valid, response_time = future.result()
                    validated_results[url] = (is_valid, response_time)
                except Exception as e:
                    validated_results[url] = (False, None)
        
        for channel_name in list(self.sources.keys()):
            valid_sources = []
            for response_time, url in self.sources[channel_name]:
                if response_time == 0:
                    valid_sources.append((0, url))
                elif url in validated_results:
                    is_valid, actual_response_time = validated_results[url]
                    if is_valid and actual_response_time is not None:
                        valid_sources.append((actual_response_time, url))
            
            valid_sources.sort(key=lambda x: x[0])
            self.sources[channel_name] = valid_sources[:10]
    
    def get_sorted_lines(self, channel_dictionary: List[str], group_title: str) -> List[str]:
        result = []
        for channel_name in channel_dictionary:
            if channel_name in self.sources and self.sources[channel_name]:
                # ç”Ÿæˆé¢‘é“ID
                channel_id = generate_channel_id(channel_name)
                
                for response_time, url in self.sources[channel_name]:
                    # åˆ›å»ºM3Uæ ¼å¼çš„è¡Œ
                    extinf_line = f'#EXTINF:-1 tvg-name="{channel_id}" tvg-logo="https://11.112114.xyz/logo/{channel_id}.png" group-title="{group_title}",{channel_name}'
                    result.append(extinf_line)
                    result.append(url)
        return result

    def get_txt_lines(self, channel_dictionary: List[str]) -> List[str]:
        result = []
        for channel_name in channel_dictionary:
            if channel_name in self.sources and self.sources[channel_name]:
                for response_time, url in self.sources[channel_name]:
                    result.append(f"{channel_name},{url}")
        return result

# å¤„ç†é¢‘é“è¡Œ
def process_channel_line(line: str, source_manager: ChannelSourceManager, channel_dictionaries: Dict[str, List[str]], skip_validation: bool = False) -> None:
    try:
        if "#genre#" not in line and "#EXTINF:" not in line and "," in line and "://" in line:
            parts = line.split(',', 1)
            if len(parts) < 2:
                return
                
            channel_name, channel_address = parts
            original_name = channel_name  # ä¿å­˜åŸå§‹åç§°
            channel_name = traditional_to_simplified(channel_name)
            channel_name = clean_channel_name(channel_name)
            
            channel_address = channel_address.strip()
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºIPv6åœ°å€ï¼Œå¦‚æœæ˜¯åˆ™è·³è¿‡
            if re.search(r'\[[0-9a-fA-F:]+\]|ipv6|240[89e]:', channel_address, re.IGNORECASE):
                return

            # åˆ†é…åˆ°æ­£ç¡®çš„é¢‘é“åˆ†ç±»
            for category, dictionary in channel_dictionaries.items():
                if channel_name in dictionary:
                    if source_manager.add_source(channel_name, channel_address, skip_validation):
                        print(f"æ·»åŠ åˆ°{category}: {channel_name}, {channel_address}")
                    return
            
            print(f"æœªåˆ†ç±»é¢‘é“: {channel_name}, {channel_address} (åŸå§‹åç§°: {original_name})")
    except Exception as e:
        print(f"å¤„ç†é¢‘é“è¡Œæ—¶å‡ºé”™: {e}")

# å¤„ç†ç›´æ’­æºæ–‡ä»¶
def process_live_file(source_manager: ChannelSourceManager, channel_dictionaries: Dict[str, List[str]]) -> None:
    print("\nå¼€å§‹å¤„ç†ç›´æ’­æºæ–‡ä»¶ assets/live.txt...")
    live_lines = read_txt_to_array('assets/live.txt')
    
    for line in live_lines:
        # è·³è¿‡æ³¨é‡Šè¡Œå’Œåˆ†ç±»æ ‡é¢˜è¡Œ
        if line.startswith('#') or line.endswith('#genre#'):
            continue
        if line.strip() and "," in line and "://" in line:
            process_channel_line(line, source_manager, channel_dictionaries, skip_validation=False)

# å¤„ç†ç²¾é€‰æºæ–‡ä»¶
def process_me_file(source_manager: ChannelSourceManager, channel_dictionaries: Dict[str, List[str]]) -> None:
    print("\nå¼€å§‹å¤„ç†ç²¾é€‰æºæ–‡ä»¶ assets/me.txt...")
    me_lines = read_txt_to_array('assets/me.txt')
    
    for line in me_lines:
        if line.strip() and "," in line and "://" in line:
            process_channel_line(line, source_manager, channel_dictionaries, skip_validation=True)

# ä¸»å‡½æ•°
def main():
    print("æ­£åœ¨è¯»å–é»‘åå•...")
    # åªè¯»å–blackhost_count.txtä½œä¸ºé»‘åå•
    blacklist = read_list_from_txt('assets/whitelist-blacklist/blackhost_count.txt')
    print(f"é»‘åå•è¡Œæ•°: {len(blacklist)}")

    print("æ­£åœ¨è¯»å–ç™½åå•...")
    whitelist = read_list_from_txt('assets/whitelist-blacklist/whitelist.txt', is_blacklist=False)
    print(f"ç™½åå•è¡Œæ•°: {len(whitelist)}")

    print("æ­£åœ¨è¯»å–é¢‘é“å­—å…¸...")
    channel_dictionaries = load_channel_dictionaries()

    # åˆ›å»ºé¢‘é“æºç®¡ç†å™¨ï¼Œä¼ å…¥é»‘åå•
    source_manager = ChannelSourceManager(blacklist=set(blacklist))

    # å¤„ç†ç›´æ’­æºæ–‡ä»¶
    process_live_file(source_manager, channel_dictionaries)

    # å¤„ç†ç²¾é€‰æºæ–‡ä»¶
    process_me_file(source_manager, channel_dictionaries)

    # éªŒè¯æ‰€æœ‰æºå¹¶é€‰æ‹©æœ€å¿«çš„10ä¸ª
    source_manager.validate_and_sort_sources()

    # è·å–å½“å‰çš„ UTC æ—¶é—´
    beijing_time = datetime.now(timezone.utc) + timedelta(hours=8)
    formatted_time = beijing_time.strftime("%Y%m%d %H:%M")
    version = formatted_time + ",https://www.cloudplains.cn/tv202303.txt"

    # åˆ†ç±»åç§°æ˜ å°„
    category_names = {
        'zh': "ç»¼åˆé¢‘é“",
        'ys': "å¤®è§†é¢‘é“", 
        'ws': "å«è§†é¢‘é“",
        'gj': "å›½é™…å°",
        'gd': "å¹¿ä¸œé¢‘é“",
        'hain': "æµ·å—é¢‘é“",
        'dy': "ç”µå½±é¢‘é“",
        'zb': "ç›´æ’­ä¸­å›½"
    }
    
    # åˆ›å»ºM3Uæ–‡ä»¶å†…å®¹
    all_m3u_lines = ["#EXTM3U", f'#EXTINF:-1 tvg-id="EPG" tvg-name="èŠ‚ç›®é¢„å‘Š" tvg-logo="https://11.112114.xyz/logo/EPG.png" group-title="èŠ‚ç›®é¢„å‘Š",èŠ‚ç›®é¢„å‘Š\nhttp://epg.51zmt.top:8000/api/diyp/?ch={{name}}&date={{date}}', '']
    
    # æ·»åŠ EPGä¿¡æ¯
    all_m3u_lines.append("#EXTGRP:èŠ‚ç›®å•ä¿¡æ¯")
    all_m3u_lines.append("#PLAYLIST:ç”µè§†ç›´æ’­")
    all_m3u_lines.append(f"#æ›´æ–°æ—¶é—´:{formatted_time}")
    all_m3u_lines.append('')

    # åˆ›å»ºTXTæ–‡ä»¶å†…å®¹
    all_txt_lines = ["æ›´æ–°æ—¶é—´,#genre#", f"{formatted_time},https://www.cloudplains.cn/tv202303.txt", ""]

    # è·å–å¤„ç†åçš„é¢‘é“æºå¹¶æ·»åŠ åˆ°M3Uå’ŒTXTæ–‡ä»¶
    total_count = 0
    categories_order = ['zh', 'ys', 'ws', 'gj', 'gd', 'hain', 'dy', 'zb']
    
    for category in categories_order:
        name = category_names[category]
        
        # æ·»åŠ åˆ°M3Uæ–‡ä»¶
        channel_m3u_lines = source_manager.get_sorted_lines(channel_dictionaries[category], name)
        count = len(channel_m3u_lines) // 2  # æ¯é¢‘é“æœ‰ä¸¤è¡Œï¼šEXTINFå’ŒURL
        total_count += count
        print(f"{name}: {count} ä¸ªé¢‘é“")
        
        # æ·»åŠ åˆ†ç±»æ ‡é¢˜åˆ°M3U
        all_m3u_lines.append(f"#========== {name} ==========#")
        all_m3u_lines.extend(channel_m3u_lines)
        all_m3u_lines.append('')
        
        # æ·»åŠ åˆ°TXTæ–‡ä»¶
        all_txt_lines.append(f"{name},#genre#")
        channel_txt_lines = source_manager.get_txt_lines(channel_dictionaries[category])
        all_txt_lines.extend(channel_txt_lines)
        all_txt_lines.append('')

    # ä¿å­˜M3Uæ–‡ä»¶
    m3u_output_file = "tv202303.m3u"
    try:
        with open(m3u_output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(all_m3u_lines))
        print(f"M3Uæ–‡ä»¶å·²ä¿å­˜åˆ°: {m3u_output_file}")
    except Exception as e:
        print(f"ä¿å­˜M3Uæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")

    # ä¿å­˜TXTæ–‡ä»¶
    txt_output_file = "tv202303.txt"
    try:
        with open(txt_output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(all_txt_lines))
        print(f"TXTæ–‡ä»¶å·²ä¿å­˜åˆ°: {txt_output_file}")
    except Exception as e:
        print(f"ä¿å­˜TXTæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")

    # æ‰§è¡Œç»“æŸæ—¶é—´
    timeend = datetime.now()
    elapsed_time = timeend - timestart
    total_seconds = elapsed_time.total_seconds()
    minutes = int(total_seconds // 60)
    seconds = int(total_seconds % 60)

    print(f"æ‰§è¡Œæ—¶é—´: {minutes} åˆ† {seconds} ç§’")
    print(f"blacklistè¡Œæ•°: {len(blacklist)}")
    print(f"{m3u_output_file}é¢‘é“æ•°: {total_count}")

if __name__ == "__main__":
    main()