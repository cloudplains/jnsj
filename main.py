import urllib.request
from urllib.parse import urlparse, quote
import re
import os
from datetime import datetime, timedelta, timezone
import random
import opencc
import ssl
import sys
import socket
import time
import concurrent.futures
import threading

# è·³è¿‡SSLè¯ä¹¦éªŒè¯
ssl._create_default_https_context = ssl._create_unverified_context

# æ‰§è¡Œå¼€å§‹æ—¶é—´
timestart = datetime.now()

# è®¾ç½®æ ‡å‡†è¾“å‡ºå’Œé”™è¯¯è¾“å‡ºç«‹å³åˆ·æ–°
sys.stdout = os.fdopen(sys.stdout.fileno(), 'w', 1)
sys.stderr = os.fdopen(sys.stderr.fileno(), 'w', 1)

print("è„šæœ¬å¼€å§‹æ‰§è¡Œ")

# è¯»å–æ–‡æœ¬æ–¹æ³•ï¼ˆæ”¯æŒå¤šç§ç¼–ç ï¼‰
def read_txt_to_array(file_name):
    try:
        # å…ˆå°è¯• UTF-8 ç¼–ç 
        with open(file_name, 'r', encoding='utf-8-sig') as file:
            lines = file.readlines()
            lines = [line.strip() for line in lines]
            return lines
    except UnicodeDecodeError:
        try:
            # å¦‚æœ UTF-8 å¤±è´¥ï¼Œå°è¯• GBK ç¼–ç 
            with open(file_name, 'r', encoding='gbk') as file:
                lines = file.readlines()
                lines = [line.strip() for line in lines]
                return lines
        except UnicodeDecodeError:
            try:
                # å¦‚æœ GBK ä¹Ÿå¤±è´¥ï¼Œå°è¯• latin-1 ç¼–ç 
                with open(file_name, 'r', encoding='latin-1') as file:
                    lines = file.readlines()
                lines = [line.strip() for line in lines]
                return lines
            except Exception as e:
                print(f"æ— æ³•ç¡®å®šåˆé€‚çš„ç¼–ç æ ¼å¼è¿›è¡Œè§£ç æ–‡ä»¶: {file_name}, é”™è¯¯: {e}")
                return []
    except FileNotFoundError:
        print(f"File '{file_name}' not found.")
        return []
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶ {file_name} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return []

# è¯»å–é»‘åå•ï¼ˆæ”¯æŒå¤šç§ç¼–ç ï¼‰
def read_blacklist_from_txt(file_path):
    blacklist = []
    try:
        # å…ˆå°è¯• UTF-8 ç¼–ç 
        with open(file_path, 'r', encoding='utf-8-sig') as file:
            lines = file.readlines()
    except UnicodeDecodeError:
        try:
            # å¦‚æœ UTF-8 å¤±è´¥ï¼Œå°è¯• GBK ç¼–ç 
            with open(file_path, 'r', encoding='gbk') as file:
                lines = file.readlines()
        except UnicodeDecodeError:
            try:
                # å¦‚æœ GBK ä¹Ÿå¤±è´¥ï¼Œå°è¯• latin-1 ç¼–ç 
                with open(file_path, 'r', encoding='latin-1') as file:
                    lines = file.readlines()
            except Exception as e:
                print(f"è¯»å–é»‘åå•æ—¶å‡ºé”™: {e}")
                return []

    # æå–URLéƒ¨åˆ†ï¼ˆé€—å·åçš„éƒ¨åˆ†ï¼‰
    for line in lines:
        line = line.strip()
        if ',' in line:
            url = line.split(',')[1].strip()
            blacklist.append(url)
        else:
            blacklist.append(line)
    return blacklist

# è¯»å–ç™½åå•ï¼ˆæ”¯æŒå¤šç§ç¼–ç ï¼‰
def read_whitelist_from_txt(file_path):
    try:
        # å…ˆå°è¯• UTF-8 ç¼–ç 
        with open(file_path, 'r', encoding='utf-8-sig') as file:
            lines = file.readlines()
    except UnicodeDecodeError:
        try:
            # å¦‚æœ UTF-8 å¤±è´¥ï¼Œå°è¯• GBK ç¼–ç 
            with open(file_path, 'r', encoding='gbk') as file:
                lines = file.readlines()
        except UnicodeDecodeError:
            try:
                # å¦‚æœ GBK ä¹Ÿå¤±è´¥ï¼Œå°è¯• latin-1 ç¼–ç 
                with open(file_path, 'r', encoding='latin-1') as file:
                    lines = file.readlines()
            except Exception as e:
                print(f"è¯»å–ç™½åå•æ—¶å‡ºé”™: {e}")
                return []

    # ä»æ¯è¡Œæå–URLéƒ¨åˆ†ï¼ˆé€—å·åçš„éƒ¨åˆ†ï¼‰
    WhiteList = []
    for line in lines:
        line = line.strip()
        if ',' in line:
            url = line.split(',')[1].strip()
            WhiteList.append(url)
        else:
            WhiteList.append(line)
    return WhiteList

print("æ­£åœ¨è¯»å–é»‘åå•...")
blacklist_auto = read_blacklist_from_txt('assets/whitelist-blacklist/blacklist_auto.txt')
black_list_manual = read_blacklist_from_txt('assets/whitelist-blacklist/blacklist_manual.txt')
combined_blacklist = set(blacklist_auto + black_list_manual)
print(f"åˆå¹¶é»‘åå•è¡Œæ•°: {len(combined_blacklist)}")

# æ‰“å°ä¸€äº›é»‘åå•URLç¤ºä¾‹
print("é»‘åå•ç¤ºä¾‹:")
for i, url in enumerate(list(combined_blacklist)[:5]):
    print(f"  {i+1}. {url}")

print("æ­£åœ¨è¯»å–ç™½åå•...")
whitelist = read_whitelist_from_txt('assets/whitelist-blacklist/whitelist.txt')
print(f"ç™½åå•è¡Œæ•°: {len(whitelist)}")
for url in whitelist:
    print(f"ç™½åå•URL: {url}")

# å®šä¹‰å¤šä¸ªå¯¹è±¡ç”¨äºå­˜å‚¨ä¸åŒå†…å®¹çš„è¡Œæ–‡æœ¬
zh_lines = []  # ç»¼åˆé¢‘é“
ys_lines = []  # å¤®è§†é¢‘é“
ws_lines = []  # å«è§†é¢‘é“
dy_lines = []  # ç”µå½±é¢‘é“
gj_lines = []  # å›½é™…å°
zb_lines = []  # ç›´æ’­ä¸­å›½
gd_lines = []  # åœ°æ–¹å°-å¹¿ä¸œé¢‘é“
hain_lines = []  # åœ°æ–¹å°-æµ·å—é¢‘é“

other_lines = []  # å…¶ä»–
other_lines_url = []  # ä¸ºé™ä½otheræ–‡ä»¶å¤§å°ï¼Œå‰”é™¤é‡å¤urlæ·»åŠ 

print("æ­£åœ¨è¯»å–é¢‘é“å­—å…¸...")
# è¯»å–æ–‡æœ¬
# ä¸»é¢‘é“
zh_dictionary = read_txt_to_array('ä¸»é¢‘é“/ç»¼åˆé¢‘é“.txt')
ys_dictionary = read_txt_to_array('ä¸»é¢‘é“/å¤®è§†é¢‘é“.txt')
ws_dictionary = read_txt_to_array('ä¸»é¢‘é“/å«è§†é¢‘é“.txt')
dy_dictionary = read_txt_to_array('ä¸»é¢‘é“/ç”µå½±.txt')
gj_dictionary = read_txt_to_array('ä¸»é¢‘é“/å›½é™…å°.txt')
zb_dictionary = read_txt_to_array('ä¸»é¢‘é“/ç›´æ’­ä¸­å›½.txt')

# åœ°æ–¹å°
gd_dictionary = read_txt_to_array('åœ°æ–¹å°/å¹¿ä¸œé¢‘é“.txt')
hain_dictionary = read_txt_to_array('åœ°æ–¹å°/æµ·å—é¢‘é“.txt')

# è‡ªå®šä¹‰æº
urls = read_txt_to_array('assets/urls.txt')
print(f"è¯»å–åˆ° {len(urls)} ä¸ªURL")
for i, url in enumerate(urls):
    print(f"  {i+1}. {url}")

# ç®€ç¹è½¬æ¢
def traditional_to_simplified(text: str) -> str:
    try:
        converter = opencc.OpenCC('t2s')
        simplified_text = converter.convert(text)
        return simplified_text
    except Exception as e:
        print(f"ç¹ç®€è½¬æ¢é”™è¯¯: {e}")
        return text

# M3Uæ ¼å¼åˆ¤æ–­
def is_m3u_content(text):
    if not text:
        return False
    lines = text.splitlines()
    if not lines:
        return False
    first_line = lines[0].strip()
    return first_line.startswith("#EXTM3U")

def convert_m3u_to_txt(m3u_content):
    # åˆ†è¡Œå¤„ç†
    lines = m3u_content.split('\n')

    # ç”¨äºå­˜å‚¨ç»“æœçš„åˆ—è¡¨
    txt_lines = []

    # ä¸´æ—¶å˜é‡ç”¨äºå­˜å‚¨é¢‘é“åç§°
    channel_name = ""

    for line in lines:
        # è¿‡æ»¤æ‰ #EXTM3U å¼€å¤´çš„è¡Œ
        if line.startswith("#EXTM3U"):
            continue
        # å¤„ç† #EXTINF å¼€å¤´çš„è¡Œ
        if line.startswith("#EXTINF"):
            # è·å–é¢‘é“åç§°ï¼ˆå‡è®¾é¢‘é“åç§°åœ¨å¼•å·åï¼‰
            channel_name = line.split(',')[-1].strip()
        # å¤„ç† URL è¡Œ
        elif line.startswith("http") or line.startswith("rtmp") or line.startswith("p3p"):
            txt_lines.append(f"{channel_name},{line.strip()}")

        # å¤„ç†åç¼€åä¸ºm3uï¼Œä½†æ˜¯å†…å®¹ä¸ºtxtçš„æ–‡ä»¶
        if "#genre#" not in line and "," in line and "://" in line:
            # å®šä¹‰æ­£åˆ™è¡¨è¾¾å¼ï¼ŒåŒ¹é…é¢‘é“åç§°,URL çš„æ ¼å¼ï¼Œå¹¶ç¡®ä¿ URL åŒ…å« "://"
            # xxxx,http://xxxxx.xx.xx
            pattern = r'^[^,]+,[^\s]+://[^\s]+$'
            if bool(re.match(pattern, line)):
                txt_lines.append(line)

    # å°†ç»“æœåˆå¹¶æˆä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œä»¥æ¢è¡Œç¬¦åˆ†éš”
    return '\n'.join(txt_lines)

# åœ¨listæ˜¯å¦å·²ç»å­˜åœ¨url
def check_url_existence(data_list, url):
    if "127.0.0.1" in url:
        return False
    # Extract URLs from the data list
    urls = [item.split(',')[1] for item in data_list if len(item.split(',')) > 1]
    return url not in urls  # å¦‚æœä¸å­˜åœ¨åˆ™è¿”å›trueï¼Œéœ€è¦

# å¤„ç†å¸¦$çš„URL
def clean_url(url):
    last_dollar_index = url.rfind('$')
    if last_dollar_index != -1:
        return url[:last_dollar_index]
    return url

# æ·»åŠ channel_nameå‰å‰”é™¤éƒ¨åˆ†ç‰¹å®šå­—ç¬¦
removal_list = ["ã€ŒIPV4ã€", "ã€ŒIPV6ã€", "[ipv6]", "[ipv4]", "_ç”µä¿¡", "ç”µä¿¡", "ï¼ˆHDï¼‰", "[è¶…æ¸…]", "é«˜æ¸…", "è¶…æ¸…", "-HD", "(HK)", "AKtv", "@", "IPV6", "ğŸğŸğŸğŸï¸", "ğŸ¦ğŸ¦ğŸ¦ğŸ¦", " ", "[BD]", "[VGA]", "[HD]", "[SD]", "(1080p)", "(720p)", "(480p)"]

def clean_channel_name(channel_name, removal_list):
    for item in removal_list:
        channel_name = channel_name.replace(item, "")
    # ä¿ç•™CCTV-æ ¼å¼
    channel_name = channel_name.replace("CCTV0", "CCTV-")
    channel_name = channel_name.replace("PLUS", "+")
    channel_name = channel_name.replace("NewTV-", "NewTV")
    channel_name = channel_name.replace("iHOT-", "iHOT")
    channel_name = channel_name.replace("NEW", "New")
    channel_name = channel_name.replace("New_", "New")
    return channel_name

# è¯»å–çº é”™é¢‘é“åç§°æ–¹æ³•
def load_corrections_name(filename):
    corrections = {}
    try:
        with open(filename, 'r', encoding='utf-8-sig') as f:
            for line in f:
                if not line.strip():
                    continue
                parts = line.strip().split(',')
                if len(parts) < 2:
                    continue
                correct_name = parts[0]
                for name in parts[1:]:
                    corrections[name] = correct_name
    except Exception as e:
        print(f"è¯»å–çº é”™æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    return corrections

# è¯»å–çº é”™æ–‡ä»¶
corrections_name = load_corrections_name('assets/corrections_name.txt')

def correct_name_data(name):
    if name in corrections_name and name != corrections_name[name]:
        name = corrections_name[name]
    return name

# æ£€æŸ¥é¢‘é“æ˜¯å¦å·²è¾¾åˆ°æœ€å¤§æºæ•°é‡
def is_channel_full(channel_name, target_list):
    count = sum(1 for line in target_list if line.startswith(channel_name + ","))
    return count >= 10

# æ£€æŸ¥URLæ˜¯å¦åœ¨ç™½åå•ä¸­
def is_whitelisted_url(url, whitelist):
    for pattern in whitelist:
        if pattern in url:
            return True
    return False

# æ£€æŸ¥æ˜¯å¦ä¸ºIPv6åœ°å€
def is_ipv6_url(url):
    """æ£€æŸ¥URLæ˜¯å¦åŒ…å«IPv6åœ°å€ç‰¹å¾"""
    # IPv6åœ°å€ç‰¹å¾ï¼šåŒ…å«å†’å·åˆ†éš”çš„åå…­è¿›åˆ¶æ•°å­—ï¼Œå¯èƒ½åŒ…å«æ–¹æ‹¬å·
    ipv6_patterns = [
        r'\[[0-9a-fA-F:]+:[0-9a-fA-F:]+\]',  # IPv6åœ°å€åœ¨æ–¹æ‹¬å·å†…
        r'://\[[0-9a-fA-F:]+\]',  # åŒ…å«IPv6åœ°å€çš„URL
        r'ipv6',  # åŒ…å«ipv6å…³é”®å­—
        r'v6\.',  # åŒ…å«v6.å­åŸŸå
        r':[0-9a-fA-F]{4}:[0-9a-fA-F]{4}:[0-9a-fA-F]{4}:[0-9a-fA-F]{4}',  # IPv6åœ°å€æ¨¡å¼
        r'240e:',  # ä¸­å›½ç”µä¿¡IPv6åœ°å€æ®µ
        r'2408:',  # ä¸­å›½è”é€šIPv6åœ°å€æ®µ
        r'2409:',  # ä¸­å›½ç§»åŠ¨IPv6åœ°å€æ®µ
    ]
    
    for pattern in ipv6_patterns:
        if re.search(pattern, url, re.IGNORECASE):
            return True
    return False

# æ£€æŸ¥æ˜¯å¦ä¸ºRTMPåè®®
def is_rtmp_url(url):
    """æ£€æŸ¥URLæ˜¯å¦ä¸ºRTMPåè®®"""
    return url.startswith('rtmp://')

# ç›´æ’­æºéªŒè¯å‡½æ•° - è¿”å›å“åº”æ—¶é—´å’Œæ˜¯å¦æˆåŠŸ
def validate_stream_url(url, timeout=3):
    """
    éªŒè¯ç›´æ’­æºæ˜¯å¦å¯è®¿é—®ï¼Œè¿”å›(æ˜¯å¦æˆåŠŸ, å“åº”æ—¶é—´)
    """
    try:
        start_time = time.time()
        
        # è§£æURLè·å–ä¸»æœºå’Œç«¯å£
        parsed_url = urlparse(url)
        host = parsed_url.hostname
        port = parsed_url.port or (443 if parsed_url.scheme == 'https' else 80)
        
        # é¦–å…ˆå°è¯•TCPè¿æ¥æµ‹è¯•
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(timeout)
        result = sock.connect_ex((host, port))
        sock.close()
        
        if result != 0:
            return False, None  # TCPè¿æ¥å¤±è´¥
            
        # å¯¹äºHTTP/HTTPSåè®®ï¼Œè¿›è¡Œæ›´è¯¦ç»†çš„éªŒè¯
        if url.startswith(('http://', 'https://')):
            try:
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                    'Accept': '*/*',
                    'Connection': 'close',
                    'Range': 'bytes=0-1024'  # åªè¯·æ±‚å°‘é‡æ•°æ®ä»¥éªŒè¯
                }
                
                req = urllib.request.Request(url, headers=headers)
                with urllib.request.urlopen(req, timeout=timeout) as response:
                    # æ£€æŸ¥çŠ¶æ€ç 
                    if response.getcode() not in [200, 206]:
                        return False, None
                    
                    # æ£€æŸ¥å†…å®¹ç±»å‹
                    content_type = response.headers.get('Content-Type', '')
                    if not any(x in content_type for x in ['video', 'audio', 'application/octet-stream', 'application/vnd.apple.mpegurl']):
                        return False, None
                        
            except urllib.error.HTTPError as e:
                # å¯¹äºéƒ¨åˆ†HTTPé”™è¯¯ï¼Œä»ç„¶å¯èƒ½æ˜¯å¯ç”¨çš„æµ
                if e.code in [200, 206, 301, 302, 307]:
                    end_time = time.time()
                    return True, end_time - start_time
                return False, None
            except Exception:
                return False, None
                
        end_time = time.time()
        return True, end_time - start_time
        
    except Exception:
        return False, None

# å¤®è§†é¢‘é“åç§°æ ‡å‡†åŒ– - ä¿®æ”¹ä¸ºä½¿ç”¨CCTV1æ ¼å¼
def standardize_cctv_name(channel_name):
    """å°†CCTVé¢‘é“åç§°æ ‡å‡†åŒ–ä¸º'CCTV-æ•°å­—+åç§°'æ ¼å¼"""
    # CCTVé¢‘é“åç§°æ˜ å°„ - ä½¿ç”¨CCTV1æ ¼å¼ä½œä¸ºé”®
    cctv_mapping = {
        'CCTV1': 'CCTV-1ç»¼åˆ',
        'CCTV2': 'CCTV-2è´¢ç»',
        'CCTV3': 'CCTV-3ç»¼è‰º',
        'CCTV4': 'CCTV-4ä¸­æ–‡å›½é™…',
        'CCTV5': 'CCTV-5ä½“è‚²',
        'CCTV5+': 'CCTV-5+ä½“è‚²èµ›äº‹',
        'CCTV6': 'CCTV-6ç”µå½±',
        'CCTV7': 'CCTV-7å›½é˜²å†›äº‹',
        'CCTV8': 'CCTV-8ç”µè§†å‰§',
        'CCTV9': 'CCTV-9çºªå½•',
        'CCTV10': 'CCTV-10ç§‘æ•™',
        'CCTV11': 'CCTV-11æˆæ›²',
        'CCTV12': 'CCTV-12ç¤¾ä¼šä¸æ³•',
        'CCTV13': 'CCTV-13æ–°é—»',
        'CCTV14': 'CCTV-14å°‘å„¿',
        'CCTV15': 'CCTV-15éŸ³ä¹',
        'CCTV16': 'CCTV-16å¥¥æ—åŒ¹å…‹',
        'CCTV17': 'CCTV-17å†œä¸šå†œæ‘'
    }
    
    # å°è¯•åŒ¹é…æ ‡å‡†åç§°
    for short_name, full_name in cctv_mapping.items():
        # ç§»é™¤é¢‘é“åç§°ä¸­çš„æ¨ªçº¿ä»¥ä¾¿åŒ¹é…
        clean_name = channel_name.replace('-', '')
        if clean_name.startswith(short_name):
            return full_name
    
    # å¦‚æœä¸æ˜¯å·²çŸ¥çš„CCTVé¢‘é“ï¼Œä¿æŒåŸæ ·
    return channel_name

# æ£€æŸ¥URLæ˜¯å¦åœ¨é»‘åå•ä¸­ï¼ˆæ›´ä¸¥æ ¼çš„æ£€æŸ¥ï¼‰
def is_blacklisted_url(url, blacklist):
    """æ£€æŸ¥URLæ˜¯å¦åœ¨é»‘åå•ä¸­ï¼Œæ”¯æŒéƒ¨åˆ†åŒ¹é…"""
    for pattern in blacklist:
        if pattern in url:
            return True
    return False

# å°†æ— æ•ˆURLæ·»åŠ åˆ°é»‘åå•
def add_to_blacklist(url, reason="æ— æ•ˆé“¾æ¥"):
    """å°†URLæ·»åŠ åˆ°é»‘åå•æ–‡ä»¶"""
    try:
        # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨é»‘åå•ä¸­
        if url in combined_blacklist:
            return
            
        # æ·»åŠ åˆ°å†…å­˜ä¸­çš„é»‘åå•
        combined_blacklist.add(url)
        
        # å†™å…¥é»‘åå•æ–‡ä»¶
        with open('assets/whitelist-blacklist/blacklist_auto.txt', 'a', encoding='utf-8') as f:
            f.write(f"{url}  # {reason} - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        print(f"å·²å°†æ— æ•ˆURLæ·»åŠ åˆ°é»‘åå•: {url} - {reason}")
    except Exception as e:
        print(f"æ·»åŠ URLåˆ°é»‘åå•æ—¶å‡ºé”™: {e}")

# é¢‘é“æºç®¡ç†å™¨ - ç”¨äºç®¡ç†æ¯ä¸ªé¢‘é“çš„æºå¹¶é€‰æ‹©æœ€å¿«çš„10ä¸ª
class ChannelSourceManager:
    def __init__(self):
        self.sources = {}  # å­—å…¸ï¼Œé”®ä¸ºé¢‘é“åç§°ï¼Œå€¼ä¸º(å“åº”æ—¶é—´, URL)åˆ—è¡¨
        self.seen_urls = set()  # ç”¨äºè·Ÿè¸ªæ‰€æœ‰å·²è§è¿‡çš„URLï¼Œé¿å…é‡å¤
        self.lock = threading.Lock()  # ç”¨äºçº¿ç¨‹å®‰å…¨
        
    def add_source(self, channel_name, url):
        # æ£€æŸ¥URLæ˜¯å¦åœ¨é»‘åå•ä¸­ï¼ˆä½¿ç”¨æ›´ä¸¥æ ¼çš„æ£€æŸ¥ï¼‰
        if is_blacklisted_url(url, combined_blacklist):
            print(f"è·³è¿‡é»‘åå•URL: {channel_name}, {url}")
            return False
            
        # æ£€æŸ¥URLæ˜¯å¦ä¸ºRTMPåè®®
        if is_rtmp_url(url):
            print(f"è·³è¿‡RTMPåè®®URL: {channel_name}, {url}")
            return False
            
        # æ£€æŸ¥URLæ˜¯å¦å·²ç»å¤„ç†è¿‡
        if url in self.seen_urls:
            print(f"è·³è¿‡é‡å¤URL: {channel_name}, {url}")
            return False
            
        self.seen_urls.add(url)
        
        with self.lock:
            if channel_name not in self.sources:
                self.sources[channel_name] = []
            self.sources[channel_name].append((float('inf'), url))  # åˆå§‹å“åº”æ—¶é—´ä¸ºæ— ç©·å¤§
        return True
        
    def validate_and_sort_sources(self, max_workers=20):
        """éªŒè¯æ‰€æœ‰æºå¹¶æ’åºï¼Œé€‰æ‹©æ¯ä¸ªé¢‘é“æœ€å¿«çš„10ä¸ªæœ‰æ•ˆæº"""
        print("å¼€å§‹éªŒè¯æ‰€æœ‰æºçš„æœ‰æ•ˆæ€§...")
        
        # æ”¶é›†æ‰€æœ‰éœ€è¦éªŒè¯çš„URL
        all_urls = []
        url_to_channel = {}
        
        for channel_name, url_list in self.sources.items():
            for _, url in url_list:
                all_urls.append(url)
                url_to_channel[url] = channel_name
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡ŒéªŒè¯URL
        validated_results = {}
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_url = {executor.submit(validate_stream_url, url): url for url in all_urls}
            for future in concurrent.futures.as_completed(future_to_url):
                url = future_to_url[future]
                try:
                    is_valid, response_time = future.result()
                    validated_results[url] = (is_valid, response_time)
                    if is_valid:
                        print(f"âœ“ æœ‰æ•ˆæº: {url_to_channel[url]}, {url} (å“åº”æ—¶é—´: {response_time:.2f}s)")
                    else:
                        print(f"âœ— æ— æ•ˆæº: {url_to_channel[url]}, {url}")
                        # å°†æ— æ•ˆURLæ·»åŠ åˆ°é»‘åå•
                        add_to_blacklist(url, "éªŒè¯å¤±è´¥")
                except Exception as e:
                    print(f"éªŒè¯URLæ—¶å‘ç”Ÿé”™è¯¯ {url}: {e}")
                    validated_results[url] = (False, None)
                    # å°†é”™è¯¯URLæ·»åŠ åˆ°é»‘åå•
                    add_to_blacklist(url, f"éªŒè¯é”™è¯¯: {e}")
        
        # æ›´æ–°æ¯ä¸ªé¢‘é“çš„æºåˆ—è¡¨
        for channel_name in list(self.sources.keys()):
            valid_sources = []
            for response_time, url in self.sources[channel_name]:
                if url in validated_results:
                    is_valid, actual_response_time = validated_results[url]
                    if is_valid and actual_response_time is not None:
                        valid_sources.append((actual_response_time, url))
            
            # æŒ‰å“åº”æ—¶é—´æ’åºå¹¶é€‰æ‹©æœ€å¿«çš„10ä¸ª
            valid_sources.sort(key=lambda x: x[0])
            self.sources[channel_name] = valid_sources[:10]
            
            print(f"é¢‘é“ {channel_name}: æ‰¾åˆ° {len(valid_sources)} ä¸ªæœ‰æ•ˆæºï¼Œä¿ç•™ {len(self.sources[channel_name])} ä¸ªæœ€å¿«æº")
    
    def get_sorted_lines(self, channel_dictionary):
        """è·å–æ’åºåçš„é¢‘é“è¡Œ"""
        result = []
        for channel_name in channel_dictionary:
            if channel_name in self.sources:
                for response_time, url in self.sources[channel_name]:
                    result.append(f"{channel_name},{url}")
        return result

# åˆ›å»ºå…¨å±€çš„é¢‘é“æºç®¡ç†å™¨
source_manager = ChannelSourceManager()

# åˆ†å‘ç›´æ’­æº
def process_channel_line(line):
    try:
        if "#genre#" not in line and "#EXTINF:" not in line and "," in line and "://" in line:
            parts = line.split(',', 1)
            if len(parts) < 2:
                return
                
            channel_name = parts[0]
            channel_name = traditional_to_simplified(channel_name)
            channel_name = clean_channel_name(channel_name, removal_list)
            channel_name = correct_name_data(channel_name).strip()

            # å¯¹å¤®è§†é¢‘é“è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†
            if channel_name.startswith('CCTV'):
                channel_name = standardize_cctv_name(channel_name)

            channel_address = clean_url(parts[1]).strip()

            # æ£€æŸ¥æ˜¯å¦ä¸ºIPv6åœ°å€ï¼Œå¦‚æœæ˜¯åˆ™è·³è¿‡
            if is_ipv6_url(channel_address):
                print(f"è·³è¿‡IPv6æº: {channel_name}, {channel_address}")
                return

            # æ£€æŸ¥æ˜¯å¦åœ¨ç™½åå•ä¸­
            is_whitelisted = is_whitelisted_url(channel_address, whitelist)
            
            # ç‰¹åˆ«å¤„ç†ç›´æ’­ä¸­å›½åˆ†ç±» - åªä¿ç•™æ˜ç¡®çš„ç›´æ’­ä¸­å›½é¢‘é“
            if channel_name in zb_dictionary:
                if is_whitelisted or not is_channel_full(channel_name, zb_lines):
                    if source_manager.add_source(channel_name, channel_address):
                        print(f"æ·»åŠ åˆ°ç›´æ’­ä¸­å›½: {channel_name}, {channel_address}")
            # æ–°å¢ç»¼åˆé¢‘é“å¤„ç†ï¼ˆæ”¾åœ¨å¤®è§†é¢‘é“å‰é¢ï¼‰
            elif channel_name in zh_dictionary:
                if is_whitelisted or not is_channel_full(channel_name, zh_lines):
                    if source_manager.add_source(channel_name, channel_address):
                        print(f"æ·»åŠ åˆ°ç»¼åˆé¢‘é“: {channel_name}, {channel_address}")
            elif channel_name in ys_dictionary:
                # å¯¹å¤®è§†é¢‘é“æ”¾å®½éªŒè¯æ¡ä»¶
                if is_whitelisted or not is_channel_full(channel_name, ys_lines):
                    if source_manager.add_source(channel_name, channel_address):
                        print(f"æ·»åŠ åˆ°å¤®è§†é¢‘é“: {channel_name}, {channel_address}")
            elif channel_name in ws_dictionary:
                # å¯¹å«è§†é¢‘é“æ”¾å®½éªŒè¯æ¡ä»¶
                if is_whitelisted or not is_channel_full(channel_name, ws_lines):
                    if source_manager.add_source(channel_name, channel_address):
                        print(f"æ·»åŠ åˆ°å«è§†é¢‘é“: {channel_name}, {channel_address}")
            elif channel_name in dy_dictionary:
                if is_whitelisted or not is_channel_full(channel_name, dy_lines):
                    if source_manager.add_source(channel_name, channel_address):
                        print(f"æ·»åŠ åˆ°ç”µå½±é¢‘é“: {channel_name}, {channel_address}")
            elif channel_name in gj_dictionary:
                if is_whitelisted or not is_channel_full(channel_name, gj_lines):
                    if source_manager.add_source(channel_name, channel_address):
                        print(f"æ·»åŠ åˆ°å›½é™…å°: {channel_name}, {channel_address}")
            elif channel_name in gd_dictionary:
                if is_whitelisted or not is_channel_full(channel_name, gd_lines):
                    if source_manager.add_source(channel_name, channel_address):
                        print(f"æ·»åŠ åˆ°å¹¿ä¸œé¢‘é“: {channel_name}, {channel_address}")
            elif channel_name in hain_dictionary:
                if is_whitelisted or not is_channel_full(channel_name, hain_lines):
                    if source_manager.add_source(channel_name, channel_address):
                        print(f"æ·»åŠ åˆ°æµ·å—é¢‘é“: {channel_name}, {channel_address}")
            else:
                print(f"æœªåˆ†ç±»é¢‘é“: {channel_name}, {channel_address}")
    except Exception as e:
        print(f"å¤„ç†é¢‘é“è¡Œæ—¶å‡ºé”™: {e}, è¡Œå†…å®¹: {line}")

# ä¿®å¤URLå¤„ç†å‡½æ•°
def safe_process_url(url):
    try:
        # å¯¹URLè¿›è¡Œç¼–ç å¤„ç†
        encoded_url = quote(url, safe=':/?&=')
        process_url(encoded_url)
    except Exception as e:
        print(f"å¤„ç†URLæ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")

def process_url(url):
    print(f"\nå¼€å§‹å¤„ç†URL: {url}")
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        }
        req = urllib.request.Request(url, headers=headers)
        # ä¿®æ”¹è¶…æ—¶æ—¶é—´ä¸º10ç§’
        with urllib.request.urlopen(req, timeout=10) as response:
            data = response.read()
            try:
                text = data.decode('utf-8')
            except UnicodeDecodeError:
                try:
                    text = data.decode('gbk')
                except UnicodeDecodeError:
                    try:
                        text = data.decode('iso-8859-1')
                    except UnicodeDecodeError:
                        print("æ— æ³•ç¡®å®šåˆé€‚çš„ç¼–ç æ ¼å¼è¿›è¡Œè§£ç ã€‚")
                        return

            if is_m3u_content(text):
                text = convert_m3u_to_txt(text)

            lines = text.split('\n')
            print(f"åŸå§‹è¡Œæ•°: {len(lines)}")
            valid_lines = 0
            for line in lines:
                if "#genre#" not in line and "," in line and "://" in line:
                    parts = line.split(',', 1)
                    if len(parts) < 2:
                        continue
                        
                    channel_name, channel_address = parts
                    if "#" not in channel_address:
                        process_channel_line(line)
                        valid_lines += 1
                    else:
                        url_list = channel_address.split('#')
                        for channel_url in url_list:
                            if "://" in channel_url:
                                newline = f'{channel_name},{channel_url}'
                                process_channel_line(newline)
                                valid_lines += 1

            print(f"æœ‰æ•ˆè¡Œæ•°: {valid_lines}")

    except Exception as e:
        print(f"å¤„ç†URLæ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")

def sort_data(order, data):
    order_dict = {name: i for i, name in enumerate(order)}

    def sort_key(line):
        name = line.split(',')[0]
        return order_dict.get(name, len(order))

    sorted_data = sorted(data, key=sort_key)
    return sorted_data

# åŠ å…¥é…ç½®çš„url
print("\nå¼€å§‹å¤„ç†æ‰€æœ‰URL...")
for url in urls:
    if url.startswith("http"):
        safe_process_url(url)

# éªŒè¯æ‰€æœ‰æºå¹¶é€‰æ‹©æœ€å¿«çš„10ä¸ª
source_manager.validate_and_sort_sources()

# è·å–å¤„ç†åçš„é¢‘é“æº
zh_lines = source_manager.get_sorted_lines(zh_dictionary)
ys_lines = source_manager.get_sorted_lines(ys_dictionary)
ws_lines = source_manager.get_sorted_lines(ws_dictionary)
dy_lines = source_manager.get_sorted_lines(dy_dictionary)
gj_lines = source_manager.get_sorted_lines(gj_dictionary)
zb_lines = source_manager.get_sorted_lines(zb_dictionary)
gd_lines = source_manager.get_sorted_lines(gd_dictionary)
hain_lines = source_manager.get_sorted_lines(hain_dictionary)

# è·å–å½“å‰çš„ UTC æ—¶é—´
utc_time = datetime.now(timezone.utc)
beijing_time = utc_time + timedelta(hours=8)
formatted_time = beijing_time.strftime("%Y%m%d %H:%M")
# ä¿®æ”¹é“¾æ¥æŒ‡å‘æ–°æ–‡ä»¶å
version = formatted_time + ",https://www.cloudplains.cn/tv202303.txt"

# æ‰“å°ç»Ÿè®¡ä¿¡æ¯
print(f"\nç»Ÿè®¡ä¿¡æ¯:")
print(f"ç»¼åˆé¢‘é“: {len(zh_lines)} è¡Œ")
print(f"å¤®è§†é¢‘é“: {len(ys_lines)} è¡Œ")
print(f"å«è§†é¢‘é“: {len(ws_lines)} è¡Œ")
print(f"ç”µå½±é¢‘é“: {len(dy_lines)} è¡Œ")
print(f"å›½é™…å°: {len(gj_lines)} è¡Œ")
print(f"ç›´æ’­ä¸­å›½: {len(zb_lines)} è¡Œ")
print(f"å¹¿ä¸œé¢‘é“: {len(gd_lines)} è¡Œ")
print(f"æµ·å—é¢‘é“: {len(hain_lines)} è¡Œ")

# åˆå¹¶æ‰€æœ‰å¯¹è±¡ä¸­çš„è¡Œæ–‡æœ¬ï¼ˆå·²ç§»é™¤IPV6é¢‘é“å’Œæ¸¯æ¾³å°é¢‘é“ï¼‰
all_lines = (["æ›´æ–°æ—¶é—´,#genre#"] + [version] + ['\n'] +
           ["ç»¼åˆé¢‘é“,#genre#"] + sort_data(zh_dictionary, zh_lines) + ['\n'] +
           ["å¤®è§†é¢‘é“,#genre#"] + sort_data(ys_dictionary, ys_lines) + ['\n'] +
           ["å«è§†é¢‘é“,#genre#"] + sort_data(ws_dictionary, ws_lines) + ['\n'] +
           ["å›½é™…å°,#genre#"] + sort_data(gj_dictionary, gj_lines) + ['\n'] +
           ["å¹¿ä¸œé¢‘é“,#genre#"] + sort_data(gd_dictionary, gd_lines) + ['\n'] +
           ["æµ·å—é¢‘é“,#genre#"] + sort_data(hain_dictionary, hain_lines) + ['\n'] +
           ["ç”µå½±é¢‘é“,#genre#"] + sort_data(dy_dictionary, dy_lines) + ['\n'] +
           ["ç›´æ’­ä¸­å›½,#genre#"] + sort_data(zb_dictionary, zb_lines) + ['\n'])

# ä¿®æ”¹è¾“å‡ºæ–‡ä»¶åä¸º tv202303.txt
output_file = "tv202303.txt"

try:
    with open(output_file, 'w', encoding='utf-8') as f:
        for line in all_lines:
            f.write(line + '\n')
    print(f"åˆå¹¶åçš„æ–‡æœ¬å·²ä¿å­˜åˆ°æ–‡ä»¶: {output_file}")

except Exception as e:
    print(f"ä¿å­˜æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")

def make_m3u(txt_file, m3u_file):
    try:
        output_text = '#EXTM3U x-tvg-url="https://epg.112114.xyz/pp.xml.gz"\n'
        with open(txt_file, "r", encoding='utf-8') as file:
            input_text = file.read()

        lines = input_text.strip().split("\n")
        group_name = ""
        for line in lines:
            parts = line.split(",")
            if len(parts) == 2 and "#genre#" in line:
                group_name = parts[0]
            elif len(parts) == 2:
                channel_name = parts[0]
                channel_url = parts[1]
                logo_url = "https://epg.112114.xyz/logo/"+channel_name+".png"
                output_text += f"#EXTINF:-1 tvg-name=\"{channel_name}\" tvg-logo=\"{logo_url}\" group-title=\"{group_name}\",{channel_name}\n"
                output_text += f"{channel_url}\n"

        with open(f"{m3u_file}", "w", encoding='utf-8') as file:
            file.write(output_text)
        print(f"M3Uæ–‡ä»¶ '{m3u_file}' ç”ŸæˆæˆåŠŸã€‚")
    except Exception as e:
        print(f"ç”ŸæˆM3Uæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")

# ä¿®æ”¹M3Uæ–‡ä»¶åä¸º tv202303.m3u
make_m3u(output_file, "tv202303.m3u")

# æ‰§è¡Œç»“æŸæ—¶é—´
timeend = datetime.now()
elapsed_time = timeend - timestart
total_seconds = elapsed_time.total_seconds()
minutes = int(total_seconds // 60)
seconds = int(total_seconds % 60)

print(f"æ‰§è¡Œæ—¶é—´: {minutes} åˆ† {seconds} ç§’")
print(f"blacklistè¡Œæ•°: {len(combined_blacklist)}")
print(f"{output_file}è¡Œæ•°: {len(all_lines)}")